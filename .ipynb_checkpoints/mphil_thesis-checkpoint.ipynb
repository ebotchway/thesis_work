{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 35>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MinMaxScaler\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# keres imports\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LSTM, Input, Dense, Dropout, Activation\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\__init__.py:21\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Implementation of the Keras API, the high-level API of TensorFlow.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03mDetailed documentation and user guides are available at\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03m[keras.io](https://keras.io).\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m models\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minput_layer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Input\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msequential\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\models\\__init__.py:18\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2022 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Keras models API.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Functional\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msequential\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\functional.py:24\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mitertools\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtensor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layout_map \u001b[38;5;28;01mas\u001b[39;00m layout_map_lib\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# imports: this cell will have all the imports used in this notebook\n",
    "import random\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.stats import bernoulli\n",
    "from bitstring import BitArray\n",
    "\n",
    "# sklearn imports\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "from sklearn.model_selection import train_test_split as split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "# sklearn genetics\n",
    "from sklearn_genetic import GASearchCV\n",
    "from sklearn_genetic.space import Integer, Categorical, Continuous\n",
    "from sklearn_genetic.plots import plot_fitness_evolution, plot_search_space\n",
    "from sklearn_genetic.callbacks import LogbookSaver, ProgressBar\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# importing the minmaxscaler to normalize data between 0 and 1\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# keres imports\n",
    "from keras.layers import LSTM, Input, Dense, Dropout, Activation\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "\n",
    "# Deap for genetic algorithm imports\n",
    "from deap import base, creator, tools, algorithms\n",
    "\n",
    "# seeding to get reproducible results with Keras and numpy\n",
    "from numpy.random import seed\n",
    "import tensorflow\n",
    "\n",
    "seed(1)\n",
    "tensorflow.random.set_seed(2)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use TeX fonts\n",
    "plt.rc(\"text\", usetex=False)\n",
    "plt.rc('font', **{'family': 'serif', 'serif': ['cmr10']})\n",
    "plt.rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})\n",
    "plt.rc('font', size=15.0)\n",
    "plt.rc('font', weight='normal')\n",
    "plt.rc('legend', fontsize=12.0)\n",
    "plt.rc('axes', grid=False) \n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read and convert csv data into a dataframe and print it out\n",
    "df_inp = pd.read_csv(\"inputs_sample_m.csv\")\n",
    "df_inp.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = pd.read_csv(\"output_sample_m.csv\")\n",
    "df_out.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = list(df_inp.columns)\n",
    "df_inp[lst].hist(figsize=(15,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from subprocess import check_output\n",
    "%config Completer.use_jedi = False\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import  mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data cleaning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inp.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inp.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inp.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inp.dropna(inplace=True)\n",
    "df_out.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inp.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_inp\n",
    "y_opt = df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, y_opt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distributions = [\n",
    "    ('Unscaled data', X),\n",
    "    ('Data after standard scaling',\n",
    "        StandardScaler().fit_transform(X)),\n",
    "    ('Data after min-max scaling',\n",
    "        MinMaxScaler().fit_transform(X)),\n",
    "    ('Data after max-abs scaling',\n",
    "        MaxAbsScaler().fit_transform(X)),\n",
    "    ('Data after robust scaling',\n",
    "        RobustScaler(quantile_range=(25, 75)).fit_transform(X)),\n",
    "    ('Data after power transformation (Yeo-Johnson)',\n",
    "     PowerTransformer(method='yeo-johnson').fit_transform(X)),\n",
    "#     ('Data after power transformation (Box-Cox)',\n",
    "#      PowerTransformer(method='box-cox').fit_transform(X)),\n",
    "    ('Data after quantile transformation (uniform pdf)',\n",
    "        QuantileTransformer(output_distribution='uniform')\n",
    "        .fit_transform(X)),\n",
    "    ('Data after quantile transformation (gaussian pdf)',\n",
    "        QuantileTransformer(output_distribution='normal')\n",
    "        .fit_transform(X)),\n",
    "    ('Data after sample-wise L2 normalizing',\n",
    "        Normalizer().fit_transform(X)),\n",
    "]\n",
    "\n",
    "# scale the output between 0 and 1 for the colorbar\n",
    "y = minmax_scale(y_opt)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = data_preprocess(X,y)\n",
    "item_idx = 1 \n",
    "title, X = distributions[item_idx]\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting into testing and training sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split(X, y_opt, test_size=0.33)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel\n",
    "# from sklearn.gaussian_process.kernels import RBF,  DotProduct, ConstantKernel as C\n",
    "pipe = RandomForestRegressor()\n",
    "\n",
    "param_grid = {'min_weight_fraction_leaf': Continuous(0.01, 0.5, distribution='log-uniform'),\n",
    "              'bootstrap': Categorical([True, False]),\n",
    "              'max_depth': Integer(2, 30), \n",
    "              'max_leaf_nodes': Integer(2, 35), \n",
    "              'n_estimators': Integer(100, 300)}\n",
    "\n",
    "# Define the GASearchCV options\n",
    "evolved_estimator = GASearchCV(\n",
    "    estimator=pipe,\n",
    "    cv=10,\n",
    "    scoring=\"r2\",\n",
    "    population_size=15,\n",
    "    generations=20,\n",
    "    tournament_size=3,\n",
    "    elitism=True,\n",
    "    keep_top_k=4,\n",
    "    crossover_probability=0.9,\n",
    "    mutation_probability=0.05,\n",
    "    param_grid=param_grid,\n",
    "#     param_grid=None,\n",
    "    criteria=\"max\",\n",
    "    algorithm=\"eaMuCommaLambda\",\n",
    "    n_jobs=-1)\n",
    "\n",
    "#Optionally, create some Callbacks\n",
    "callbacks = [LogbookSaver(checkpoint_path=\"./logbook.pkl\"), ProgressBar()]\n",
    "\n",
    "# Fit the model and see some results\n",
    "evolved_estimator.fit(X_train, y_train, callbacks=callbacks)\n",
    "y_predict_ga = evolved_estimator.predict(X_test)\n",
    "r_squared = r2_score(y_test, y_predict_ga)\n",
    "\n",
    "print(evolved_estimator.best_params_)\n",
    "print(\"r-squared: \", \"{:.2f}\".format(r_squared))\n",
    "print(\"Best k solutions: \", evolved_estimator.hof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = plot_fitness_evolution(evolved_estimator, metric=\"fitness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc(\"text\", usetex=False)\n",
    "plot_search_space(evolved_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[6,5])\n",
    "plt.scatter(y_test, y_predict_ga, s=90)\n",
    "plt.xlim(left=0.86)\n",
    "plt.ylim(bottom=0.88, top=0.96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc(\"text\", usetex=True)\n",
    "import scipy \n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=[8,5], dpi=80)\n",
    "\n",
    "fig.suptitle(r'Model Performance of Hydrogen')\n",
    "ax1.scatter(y_test, y_predict_ga, s=120, alpha=0.5)\n",
    "ax1.set_xlim(left=0.86)\n",
    "ax1.set_ylim(bottom=0.88, top=0.96)\n",
    "ax1.set_xlabel(r'Scaled Actual Output')\n",
    "ax1.set_ylabel(r'Scaled Predicted Output')\n",
    "ax1.set_title(r'$R^2 = {:.4g}$'.format(r2_score(y_test, y_predict_ga)))\n",
    "\n",
    "# best fit of data\n",
    "data_res = y_test - y_predict_ga \n",
    "(mu, sigma) = norm.fit(data_res[data_res > -0.08])\n",
    "\n",
    "# the histogram of the data\n",
    "n, bins, patches =  ax2.hist(y_test - y_predict_ga, 30, density=1, alpha=0.5)\n",
    "\n",
    "# add a 'best fit' line\n",
    "best_fit_line = scipy.stats.norm.pdf(bins, mu, sigma)\n",
    "l = plt.plot(bins, best_fit_line, 'r--', linewidth=2)\n",
    "\n",
    "\n",
    "ax2.set_xlim(left=-0.08)\n",
    "ax2.set_xlabel(r'Residual')\n",
    "ax2.set_ylabel(r'Frequency')\n",
    "ax2.set_title(r'$\\sigma = {:.4f}$'.format(mean_squared_error(y_test, y_predict_ga, squared=False)))\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neural_network\n",
    "\n",
    "pipe = neural_network.MLPRegressor()\n",
    "\n",
    "param_grid = {\n",
    "#     'min_weight_fraction_leaf': Continuous(0.01, 0.5, distribution='log-uniform'),\n",
    "#               'bootstrap': Categorical([True, False]),\n",
    "#               'max_depth': Integer(2, 30), \n",
    "#               'max_leaf_nodes': Integer(2, 35), \n",
    "#               'n_estimators': Integer(100, 300)             \n",
    "          'solver': Categorical(['lbfgs', 'sgd', 'adam']),\n",
    "          'max_iter': Integer(500,1500),\n",
    "          'alpha': Continuous(10.0**(-7), 10.0**(-1), distribution='log-uniform'),\n",
    "          'hidden_layer_sizes': Integer(5, 12),\n",
    "          'random_state':Integer(0, 9)\n",
    "             \n",
    "             }\n",
    "\n",
    "# Define the GASearchCV options\n",
    "evolved_estimator = GASearchCV(\n",
    "    estimator=pipe,\n",
    "    cv=10,\n",
    "    scoring=\"r2\",\n",
    "    population_size=15,\n",
    "    generations=20,\n",
    "    tournament_size=3,\n",
    "    elitism=True,\n",
    "    keep_top_k=4,\n",
    "    crossover_probability=0.9,\n",
    "    mutation_probability=0.05,\n",
    "    param_grid=param_grid,\n",
    "#     param_grid=None,\n",
    "    criteria=\"max\",\n",
    "    algorithm=\"eaMuCommaLambda\",\n",
    "    n_jobs=-1)\n",
    "\n",
    "#Optionally, create some Callbacks\n",
    "callbacks = [LogbookSaver(checkpoint_path=\"./logbook.pkl\"), ProgressBar()]\n",
    "\n",
    "# Fit the model and see some results\n",
    "evolved_estimator.fit(X_train, y_train, callbacks=callbacks)\n",
    "y_predict_ga = evolved_estimator.predict(X_test)\n",
    "r_squared = r2_score(y_test, y_predict_ga)\n",
    "\n",
    "print(evolved_estimator.best_params_)\n",
    "print(\"r-squared: \", \"{:.2f}\".format(r_squared))\n",
    "print(\"Best k solutions: \", evolved_estimator.hof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = plot_fitness_evolution(evolved_estimator, metric=\"fitness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc(\"text\", usetex=False)\n",
    "plot_search_space(evolved_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[6,5])\n",
    "plt.scatter(y_test, y_predict_ga, s=90)\n",
    "plt.xlim(left=0.86)\n",
    "plt.ylim(bottom=0.88, top=0.96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc(\"text\", usetex=False)\n",
    "import scipy \n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=[8,5], dpi=80)\n",
    "\n",
    "fig.suptitle(r'Model Performance of Hydrogen')\n",
    "ax1.scatter(y_test, y_predict_ga, s=120, alpha=0.5)\n",
    "ax1.set_xlim(left=0.86)\n",
    "ax1.set_ylim(bottom=0.88, top=0.96)\n",
    "ax1.set_xlabel(r'Scaled Actual Output')\n",
    "ax1.set_ylabel(r'Scaled Predicted Output')\n",
    "ax1.set_title(r'$R^2 = {:.4g}$'.format(r2_score(y_test, y_predict_ga)))\n",
    "\n",
    "# best fit of data\n",
    "data_res = y_test - y_predict_ga \n",
    "(mu, sigma) = norm.fit(data_res[data_res > -0.08])\n",
    "\n",
    "# the histogram of the data\n",
    "n, bins, patches =  ax2.hist(y_test - y_predict_ga, 30, density=1, alpha=0.5)\n",
    "\n",
    "# add a 'best fit' line\n",
    "best_fit_line = scipy.stats.norm.pdf(bins, mu, sigma)\n",
    "l = plt.plot(bins, best_fit_line, 'r--', linewidth=2)\n",
    "\n",
    "\n",
    "ax2.set_xlim(left=-0.08)\n",
    "ax2.set_xlabel(r'Residual')\n",
    "ax2.set_ylabel(r'Frequency')\n",
    "ax2.set_title(r'$\\sigma = {:.4f}$'.format(mean_squared_error(y_test, y_predict_ga, squared=False)))\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import BayesianRidge\n",
    "\n",
    "param_grid = {'n_iter': Integer(300, 500),\n",
    "              'tol': Continuous(0.0001, 0.1),\n",
    "              'alpha_1': Continuous(1.0e-7, 1e-1),\n",
    "              'alpha_2': Continuous(1.0e-7, 1e-1),\n",
    "              'lambda_1': Continuous(1.0e-7, 1e-1),\n",
    "              'lambda_2': Continuous(1.0e-7, 1e-1),\n",
    "              'normalize': Categorical([False, True])}\n",
    "\n",
    "\n",
    "\n",
    "pipe = BayesianRidge()\n",
    "\n",
    "# param_grid = {'min_weight_fraction_leaf': Continuous(0.01, 0.5, distribution='log-uniform'),\n",
    "#               'bootstrap': Categorical([True, False]),\n",
    "#               'max_depth': Integer(2, 30), \n",
    "#               'max_leaf_nodes': Integer(2, 35), \n",
    "#               'n_estimators': Integer(100, 300)}\n",
    "# Create the CV strategy and define the param grid\n",
    "cv = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "# Define the GASearchCV options\n",
    "evolved_estimator = GASearchCV(\n",
    "    estimator=pipe,\n",
    "    cv=cv,\n",
    "    scoring=\"r2\",\n",
    "    population_size=15,\n",
    "    generations=20,\n",
    "    tournament_size=3,\n",
    "    elitism=True,\n",
    "    keep_top_k=4,\n",
    "    crossover_probability=0.9,\n",
    "    mutation_probability=0.05,\n",
    "    param_grid=param_grid,\n",
    "#     param_grid=None,\n",
    "    criteria=\"max\",\n",
    "    algorithm=\"eaMuCommaLambda\",\n",
    "    n_jobs=-1)\n",
    "\n",
    "#Optionally, create some Callbacks\n",
    "callbacks = [LogbookSaver(checkpoint_path=\"./logbook.pkl\"), ProgressBar()]\n",
    "\n",
    "# Fit the model and see some results\n",
    "evolved_estimator.fit(X_train, y_train, callbacks=callbacks)\n",
    "y_predict_ga = evolved_estimator.predict(X_test)\n",
    "r_squared = r2_score(y_test, y_predict_ga)\n",
    "\n",
    "print(evolved_estimator.best_params_)\n",
    "print(\"r-squared: \", \"{:.2f}\".format(r_squared))\n",
    "print(\"Best k solutions: \", evolved_estimator.hof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = plot_fitness_evolution(evolved_estimator, metric=\"fitness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc(\"text\", usetex=False)\n",
    "plot_search_space(evolved_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[6,5])\n",
    "plt.scatter(y_test, y_predict_ga, s=90)\n",
    "plt.xlim(left=0.86)\n",
    "plt.ylim(bottom=0.88, top=0.96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc(\"text\", usetex=False)\n",
    "import scipy \n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=[8,5], dpi=80)\n",
    "\n",
    "fig.suptitle(r'Model Performance of Hydrogen')\n",
    "ax1.scatter(y_test, y_predict_ga, s=120, alpha=0.5)\n",
    "ax1.set_xlim(left=0.86)\n",
    "ax1.set_ylim(bottom=0.88, top=0.96)\n",
    "ax1.set_xlabel(r'Scaled Actual Output')\n",
    "ax1.set_ylabel(r'Scaled Predicted Output')\n",
    "ax1.set_title(r'$R^2 = {:.4g}$'.format(r2_score(y_test, y_predict_ga)))\n",
    "\n",
    "# best fit of data\n",
    "data_res = y_test - y_predict_ga \n",
    "(mu, sigma) = norm.fit(data_res[data_res > -0.08])\n",
    "\n",
    "# the histogram of the data\n",
    "n, bins, patches =  ax2.hist(y_test - y_predict_ga, 30, density=1, alpha=0.5)\n",
    "\n",
    "# add a 'best fit' line\n",
    "best_fit_line = scipy.stats.norm.pdf(bins, mu, sigma)\n",
    "l = plt.plot(bins, best_fit_line, 'r--', linewidth=2)\n",
    "\n",
    "\n",
    "ax2.set_xlim(left=-0.08)\n",
    "ax2.set_xlabel(r'Residual')\n",
    "ax2.set_ylabel(r'Frequency')\n",
    "ax2.set_title(r'$\\sigma = {:.4f}$'.format(mean_squared_error(y_test, y_predict_ga, squared=False)))\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "b119d6cc3476f76004f7d264cfcd5d8d36e9da707c7162ae9969d1410f0eccce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
