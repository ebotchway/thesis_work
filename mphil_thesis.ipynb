{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports: this cell will have all the imports used in this notebook\n",
    "import random\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.stats import bernoulli\n",
    "from bitstring import BitArray\n",
    "\n",
    "# sklearn imports\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "from sklearn.model_selection import train_test_split as split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# sklearn\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# sklearn genetics\n",
    "from sklearn_genetic import GASearchCV\n",
    "from sklearn_genetic.space import Integer, Categorical, Continuous\n",
    "from sklearn_genetic.plots import plot_fitness_evolution, plot_search_space\n",
    "from sklearn_genetic.callbacks import LogbookSaver, ProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sklearn \n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# importing the minmaxscaler to normalize data between 0 and 1\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# keres imports\n",
    "from keras.layers import LSTM, Input, Dense, Dropout, Activation\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "\n",
    "# Deap for genetic algorithm imports\n",
    "from deap import base, creator, tools, algorithms\n",
    "\n",
    "# seeding to get reproducible results with Keras and numpy\n",
    "from numpy.random import seed\n",
    "import tensorflow\n",
    "\n",
    "%matplotlib inline\n",
    "from subprocess import check_output\n",
    "%config Completer.use_jedi = False\n",
    "\n",
    "# preprocessing \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import  mean_squared_error, r2_score\n",
    "\n",
    "seed(1)\n",
    "tensorflow.random.set_seed(2)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set image printing features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use TeX fonts\n",
    "plt.rc(\"text\", usetex=False)\n",
    "plt.rc('font', **{'family': 'serif', 'serif': ['cmr10']})\n",
    "plt.rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})\n",
    "plt.rc('font', size=6.0)\n",
    "plt.rc('font', weight='normal')\n",
    "plt.rc('legend', fontsize=4.5)\n",
    "plt.rc('axes', grid=False) \n",
    "plt.rcParams['axes.labelsize'] = 6\n",
    "plt.rcParams['xtick.labelsize'] = 4.5\n",
    "plt.rcParams['ytick.labelsize'] = 4.5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define input and output dataframes and view them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read and convert csv data into a dataframe and print it out\n",
    "df_inp = pd.read_csv(\"inputs_sample_m.csv\")\n",
    "df_inp.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = pd.read_csv(\"output_sample_m.csv\")\n",
    "df_out.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = list(df_inp.columns)\n",
    "df_inp[lst].hist(figsize=(15,10))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfb = pd.read_csv(\"base_sample.csv\")\n",
    "dfb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfb.plot(x='Time', y='H2')\n",
    "plt.xlabel(\"Time/ hours\")\n",
    "plt.ylabel(\"Hydrogen/ quantity generated\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfb.plot(x='Time', y='Press')\n",
    "plt.xlabel(\"Time/ hours\")\n",
    "plt.ylabel(\"Pressure/ Pa\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfb.plot(x='Time', y='Temp')\n",
    "plt.xlabel(\"Time/ hours\")\n",
    "plt.ylabel(\"Tempreature/ K\")\n",
    "plt.grid()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data cleaning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will use the combined data now.\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "df.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we check for n/a values\n",
    "df.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we check for duplicate values\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale all the data \n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# scale all data\n",
    "df_scaled = scaler.fit_transform(df.values)\n",
    "df_scaled\n",
    "\n",
    "# turn array scaled to dataframe\n",
    "df_sc = pd.DataFrame(df_scaled, columns = [df.columns])\n",
    "df_sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the missing data\n",
    "import missingno as msno\n",
    "\n",
    "msno.matrix(df_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize outliers\n",
    "sn.boxplot( data=df_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.stats.mstats import winsorize\n",
    "# from scipy.stats import mstats\n",
    "\n",
    "# # winzorize the srv lamda\n",
    "# df_l = df_sc['SRV LAMDA'].values\n",
    "# df_lw = mstats.winsorize(df_l, limits=[df_sc['SRV LAMDA'].quantile(0.05).values[0], df_sc['SRV LAMDA'].quantile(0.95).values[0]])\n",
    "\n",
    "# df_sc['SRV LAMDA'] =df_lw.data\n",
    "# sn.boxplot( data=df_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split(X, y, test_size=0.33)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel\n",
    "from sklearn.gaussian_process.kernels import RBF,  DotProduct, ConstantKernel as C\n",
    "pipe = RandomForestRegressor()\n",
    "\n",
    "param_grid = {'min_weight_fraction_leaf': Continuous(0.01, 0.5, distribution='log-uniform'),\n",
    "              'bootstrap': Categorical([True, False]),\n",
    "              'max_depth': Integer(2, 30), \n",
    "              'max_leaf_nodes': Integer(2, 35), \n",
    "              'n_estimators': Integer(100, 300)}\n",
    "\n",
    "# Define the GASearchCV options\n",
    "evolved_estimator = GASearchCV(\n",
    "    estimator=pipe,\n",
    "    cv=10,\n",
    "    scoring=\"r2\",\n",
    "    population_size=15,\n",
    "    generations=20,\n",
    "    tournament_size=3,\n",
    "    elitism=True,\n",
    "    keep_top_k=4,\n",
    "    crossover_probability=0.9,\n",
    "    mutation_probability=0.05,\n",
    "    param_grid=param_grid,\n",
    "    # param_grid=None,\n",
    "    criteria=\"max\",\n",
    "    algorithm=\"eaMuCommaLambda\",\n",
    "    n_jobs=-1)\n",
    "\n",
    "# Optionally, create some Callbacks\n",
    "callbacks = [LogbookSaver(checkpoint_path=\"./logbook.pkl\"), ProgressBar()]\n",
    "\n",
    "# Fit the model and see some results\n",
    "evolved_estimator.fit(X_train, y_train, callbacks=callbacks)\n",
    "y_predict_ga = evolved_estimator.predict(X_test)\n",
    "r_squared = r2_score(y_test, y_predict_ga)\n",
    "\n",
    "print(evolved_estimator.best_params_)\n",
    "print(\"r-squared: \", \"{:.2f}\".format(r_squared))\n",
    "print(\"Best k solutions: \", evolved_estimator.hof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = plot_fitness_evolution(evolved_estimator, metric=\"fitness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc(\"text\", usetex=False)\n",
    "plot_search_space(evolved_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[6,5])\n",
    "plt.scatter(y_test, y_predict_ga, s=90)\n",
    "# plt.xlim(left=0.86)\n",
    "# plt.ylim(bottom=0.88, top=0.96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc(\"text\", usetex=False)\n",
    "import scipy \n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=[8,5], dpi=80)\n",
    "\n",
    "fig.suptitle(r'Model Performance of Hydrogen')\n",
    "ax1.scatter(y_test, y_predict_ga, s=120, alpha=0.5)\n",
    "ax1.set_xlim(left=0.86)\n",
    "ax1.set_ylim(bottom=0.88, top=0.96)\n",
    "ax1.set_xlabel(r'Scaled Actual Output')\n",
    "ax1.set_ylabel(r'Scaled Predicted Output')\n",
    "ax1.set_title(r'$R^2 = {:.4g}$'.format(r2_score(y_test, y_predict_ga)))\n",
    "\n",
    "# best fit of data\n",
    "data_res = y_test - y_predict_ga \n",
    "(mu, sigma) = stats.norm.fit(data_res[data_res > -0.08])\n",
    "\n",
    "# the histogram of the data\n",
    "n, bins, patches =  ax2.hist(y_test - y_predict_ga, 30, density=1, alpha=0.5)\n",
    "\n",
    "# add a 'best fit' line\n",
    "best_fit_line = scipy.stats.norm.pdf(bins, mu, sigma)\n",
    "l = plt.plot(bins, best_fit_line, 'r--', linewidth=2)\n",
    "\n",
    "\n",
    "ax2.set_xlim(left=-0.08)\n",
    "ax2.set_xlabel(r'Residual')\n",
    "ax2.set_ylabel(r'Frequency')\n",
    "ax2.set_title(r'$\\sigma = {:.4f}$'.format(mean_squared_error(y_test, y_predict_ga, squared=False)))\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neural_network\n",
    "\n",
    "pipe = neural_network.MLPRegressor()\n",
    "\n",
    "param_grid = {\n",
    "#     'min_weight_fraction_leaf': Continuous(0.01, 0.5, distribution='log-uniform'),\n",
    "#               'bootstrap': Categorical([True, False]),\n",
    "#               'max_depth': Integer(2, 30), \n",
    "#               'max_leaf_nodes': Integer(2, 35), \n",
    "#               'n_estimators': Integer(100, 300)             \n",
    "          'solver': Categorical(['lbfgs', 'sgd', 'adam']),\n",
    "          'max_iter': Integer(500,1500),\n",
    "          'alpha': Continuous(10.0**(-7), 10.0**(-1), distribution='log-uniform'),\n",
    "          'hidden_layer_sizes': Integer(5, 12),\n",
    "          'random_state':Integer(0, 9)\n",
    "             \n",
    "             }\n",
    "\n",
    "# Define the GASearchCV options\n",
    "evolved_estimator = GASearchCV(\n",
    "    estimator=pipe,\n",
    "    cv=10,\n",
    "    scoring=\"r2\",\n",
    "    population_size=15,\n",
    "    generations=20,\n",
    "    tournament_size=3,\n",
    "    elitism=True,\n",
    "    keep_top_k=4,\n",
    "    crossover_probability=0.9,\n",
    "    mutation_probability=0.05,\n",
    "    param_grid=param_grid,\n",
    "#     param_grid=None,\n",
    "    criteria=\"max\",\n",
    "    algorithm=\"eaMuCommaLambda\",\n",
    "    n_jobs=-1)\n",
    "\n",
    "#Optionally, create some Callbacks\n",
    "callbacks = [LogbookSaver(checkpoint_path=\"./logbook.pkl\"), ProgressBar()]\n",
    "\n",
    "# Fit the model and see some results\n",
    "evolved_estimator.fit(X_train, y_train, callbacks=callbacks)\n",
    "y_predict_ga = evolved_estimator.predict(X_test)\n",
    "r_squared = r2_score(y_test, y_predict_ga)\n",
    "\n",
    "print(evolved_estimator.best_params_)\n",
    "print(\"r-squared: \", \"{:.2f}\".format(r_squared))\n",
    "print(\"Best k solutions: \", evolved_estimator.hof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = plot_fitness_evolution(evolved_estimator, metric=\"fitness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc(\"text\", usetex=False)\n",
    "plot_search_space(evolved_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[6,5])\n",
    "plt.scatter(y_test, y_predict_ga, s=90)\n",
    "# plt.xlim(left=0.86)\n",
    "# plt.ylim(bottom=0.88, top=0.96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc(\"text\", usetex=False)\n",
    "import scipy \n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=[8,5], dpi=80)\n",
    "\n",
    "fig.suptitle(r'Model Performance of Hydrogen')\n",
    "ax1.scatter(y_test, y_predict_ga, s=120, alpha=0.5)\n",
    "ax1.set_xlim(left=0.86)\n",
    "ax1.set_ylim(bottom=0.88, top=0.96)\n",
    "ax1.set_xlabel(r'Scaled Actual Output')\n",
    "ax1.set_ylabel(r'Scaled Predicted Output')\n",
    "ax1.set_title(r'$R^2 = {:.4g}$'.format(r2_score(y_test, y_predict_ga)))\n",
    "\n",
    "# best fit of data\n",
    "data_res = y_test - y_predict_ga \n",
    "(mu, sigma) = stats.norm.fit(data_res[data_res > -0.08])\n",
    "\n",
    "# the histogram of the data\n",
    "n, bins, patches =  ax2.hist(y_test - y_predict_ga, 30, density=1, alpha=0.5)\n",
    "\n",
    "# add a 'best fit' line\n",
    "best_fit_line = scipy.stats.norm.pdf(bins, mu, sigma)\n",
    "l = plt.plot(bins, best_fit_line, 'r--', linewidth=2)\n",
    "\n",
    "\n",
    "ax2.set_xlim(left=-0.08)\n",
    "ax2.set_xlabel(r'Residual')\n",
    "ax2.set_ylabel(r'Frequency')\n",
    "ax2.set_title(r'$\\sigma = {:.4f}$'.format(mean_squared_error(y_test, y_predict_ga, squared=False)))\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import BayesianRidge\n",
    "\n",
    "param_grid = {'n_iter': Integer(300, 500),\n",
    "              'tol': Continuous(0.0001, 0.1),\n",
    "              'alpha_1': Continuous(1.0e-7, 1e-1),\n",
    "              'alpha_2': Continuous(1.0e-7, 1e-1),\n",
    "              'lambda_1': Continuous(1.0e-7, 1e-1),\n",
    "              'lambda_2': Continuous(1.0e-7, 1e-1),\n",
    "              'normalize': Categorical([False, True])}\n",
    "\n",
    "\n",
    "\n",
    "pipe = BayesianRidge()\n",
    "\n",
    "# param_grid = {'min_weight_fraction_leaf': Continuous(0.01, 0.5, distribution='log-uniform'),\n",
    "#               'bootstrap': Categorical([True, False]),\n",
    "#               'max_depth': Integer(2, 30), \n",
    "#               'max_leaf_nodes': Integer(2, 35), \n",
    "#               'n_estimators': Integer(100, 300)}\n",
    "# Create the CV strategy and define the param grid\n",
    "cv = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "# Define the GASearchCV options\n",
    "evolved_estimator = GASearchCV(\n",
    "    estimator=pipe,\n",
    "    cv=cv,\n",
    "    scoring=\"r2\",\n",
    "    population_size=15,\n",
    "    generations=20,\n",
    "    tournament_size=3,\n",
    "    elitism=True,\n",
    "    keep_top_k=4,\n",
    "    crossover_probability=0.9,\n",
    "    mutation_probability=0.05,\n",
    "    param_grid=param_grid,\n",
    "#     param_grid=None,\n",
    "    criteria=\"max\",\n",
    "    algorithm=\"eaMuCommaLambda\",\n",
    "    n_jobs=-1)\n",
    "\n",
    "#Optionally, create some Callbacks\n",
    "callbacks = [LogbookSaver(checkpoint_path=\"./logbook.pkl\"), ProgressBar()]\n",
    "\n",
    "# Fit the model and see some results\n",
    "evolved_estimator.fit(X_train, y_train, callbacks=callbacks)\n",
    "y_predict_ga = evolved_estimator.predict(X_test)\n",
    "r_squared = r2_score(y_test, y_predict_ga)\n",
    "\n",
    "print(evolved_estimator.best_params_)\n",
    "print(\"r-squared: \", \"{:.2f}\".format(r_squared))\n",
    "print(\"Best k solutions: \", evolved_estimator.hof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = plot_fitness_evolution(evolved_estimator, metric=\"fitness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc(\"text\", usetex=False)\n",
    "plot_search_space(evolved_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[6,5])\n",
    "plt.scatter(y_test, y_predict_ga, s=90)\n",
    "plt.xlim(left=0.86)\n",
    "plt.ylim(bottom=0.88, top=0.96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc(\"text\", usetex=False)\n",
    "import scipy \n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=[8,5], dpi=80)\n",
    "\n",
    "fig.suptitle(r'Model Performance of Hydrogen')\n",
    "ax1.scatter(y_test, y_predict_ga, s=120, alpha=0.5)\n",
    "ax1.set_xlim(left=0.86)\n",
    "ax1.set_ylim(bottom=0.88, top=0.96)\n",
    "ax1.set_xlabel(r'Scaled Actual Output')\n",
    "ax1.set_ylabel(r'Scaled Predicted Output')\n",
    "ax1.set_title(r'$R^2 = {:.4g}$'.format(r2_score(y_test, y_predict_ga)))\n",
    "\n",
    "# best fit of data\n",
    "data_res = y_test - y_predict_ga \n",
    "(mu, sigma) = stats.norm.fit(data_res[data_res > -0.08])\n",
    "\n",
    "# the histogram of the data\n",
    "n, bins, patches =  ax2.hist(y_test - y_predict_ga, 30, density=1, alpha=0.5)\n",
    "\n",
    "# add a 'best fit' line\n",
    "best_fit_line = scipy.stats.norm.pdf(bins, mu, sigma)\n",
    "l = plt.plot(bins, best_fit_line, 'r--', linewidth=2)\n",
    "\n",
    "\n",
    "ax2.set_xlim(left=-0.08)\n",
    "ax2.set_xlabel(r'Residual')\n",
    "ax2.set_ylabel(r'Frequency')\n",
    "ax2.set_title(r'$\\sigma = {:.4f}$'.format(mean_squared_error(y_test, y_predict_ga, squared=False)))\n",
    "\n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "b119d6cc3476f76004f7d264cfcd5d8d36e9da707c7162ae9969d1410f0eccce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
