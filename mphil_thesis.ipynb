{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports: this cell will have all the imports used in this notebook\n",
    "import random\n",
    "import time\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import bernoulli\n",
    "from bitstring import BitArray\n",
    "\n",
    "# sklearn imports\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "from sklearn.model_selection import train_test_split as split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# sklearn\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# sklearn genetics\n",
    "from sklearn_genetic import GASearchCV\n",
    "from sklearn_genetic.space import Integer, Categorical, Continuous\n",
    "from sklearn_genetic.plots import plot_fitness_evolution, plot_search_space\n",
    "from sklearn_genetic.callbacks import LogbookSaver, ProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sklearn\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# importing the minmaxscaler to normalize data between 0 and 1\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# keres imports\n",
    "from keras.layers import LSTM, Input, Dense, Dropout, Activation\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "\n",
    "# Deap for genetic algorithm imports\n",
    "from deap import base, creator, tools, algorithms\n",
    "\n",
    "# seeding to get reproducible results with Keras and numpy\n",
    "from numpy.random import seed\n",
    "import tensorflow\n",
    "\n",
    "# used for displaying missing data\n",
    "import missingno as msno\n",
    "\n",
    "%matplotlib inline\n",
    "from subprocess import check_output\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# preprocessing \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel\n",
    "from sklearn.gaussian_process.kernels import RBF,  DotProduct, ConstantKernel as C\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from scipy.stats import loguniform\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import  mean_squared_error, r2_score, make_scorer\n",
    "\n",
    "seed(1)\n",
    "tensorflow.random.set_seed(2)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set image printing features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use TeX fonts\n",
    "plt.rc(\"text\", usetex=False)\n",
    "plt.rc('font', **{'family': 'serif', 'serif': ['cmr10']})\n",
    "plt.rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})\n",
    "plt.rc('font', size=7.0)\n",
    "plt.rc('font', weight='normal')\n",
    "plt.rc('legend', fontsize=5)\n",
    "plt.rc('axes', grid=False)\n",
    "plt.rcParams['axes.labelsize'] = 7\n",
    "plt.rcParams['xtick.labelsize'] = 5\n",
    "plt.rcParams['ytick.labelsize'] = 5\n",
    "plt.rcParams['figure.figsize'] = [11, 6.5]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define input and output dataframes and view them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read and convert csv data into a dataframe and print it out\n",
    "df_inp = pd.read_csv(\"inputs_sample_m.csv\")\n",
    "df_inp = df_inp.dropna()\n",
    "df_inp.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = pd.read_csv(\"output_sample_m.csv\")\n",
    "df_out = df_out.dropna()\n",
    "df_out.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = list(df_inp.columns)\n",
    "df_inp[lst].hist(figsize=(15,10))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrMatrix = df_inp.corr()\n",
    "print(corrMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn.heatmap(corrMatrix, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding correlation between the inputs and outputs\n",
    "corrl = df_inp.corrwith(df_out[\"H2\"])   # we first find for Hydrogen production\n",
    "corr2 = df_inp.corrwith(df_out[\"Temp\"])  # we then find for Temprature\n",
    "corr3 = df_inp.corrwith(df_out[\"Press\"])   # we then find for Pressure\n",
    "print(\"Correlation of the input data with Hydrogen production\")\n",
    "print(corrl)\n",
    "print(\"\\n\")\n",
    "print(\"Correlation of the input data with Temprature\")\n",
    "print(corr2)\n",
    "print(\"\\n\")\n",
    "print(\"Correlation of the input data with Pressure\")\n",
    "print(corr3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ploting the pearson's correlation in a horizontal bar graph between the inputs and each output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now plotting Pearson's r between inputs and outputs\n",
    "inputs_or = df_inp.columns.to_list()\n",
    "\n",
    "plt.barh(inputs_or,corrl,color='blue') # blue for plot for hydrogen production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.barh(inputs_or,corr2,color='red') # red for plot for Tempreature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.barh(inputs_or,corr3,color='green') # green for plot for pressure"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the Spearman's P Values between the inputs and each output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the p-value of the data and print it out\n",
    "pph_val = []\n",
    "for i in inputs_or:\n",
    "    pcor, pval = stats.spearmanr(df_inp[i],df_out[\"H2\"])   # we first find for Hydrogen production\n",
    "    pph_val.append(pval)\n",
    "print(pph_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.barh(inputs_or,pph_val,color='blue') # blue for p-values of input with hydrogen production\n",
    "plt.axvline(x=0.05,color='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the p-value of the data and print it out\n",
    "ppt_val = []\n",
    "for i in inputs_or:\n",
    "    pcor, pval = stats.spearmanr(df_inp[i],df_out[\"Temp\"])   # then find for temperature\n",
    "    ppt_val.append(pval)\n",
    "print(ppt_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.barh(inputs_or,ppt_val,color='red') # red for p-values of input with Tempreature\n",
    "plt.axvline(x=0.05,color='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the p-value of the data and print it out\n",
    "ppp_val = []\n",
    "for i in inputs_or:\n",
    "    pcor, pval = stats.spearmanr(df_inp[i],df_out[\"Press\"])   # then find for pressure\n",
    "    ppp_val.append(pval)\n",
    "print(ppp_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.barh(inputs_or,ppp_val,color='green') # green for p-values of input with pressure\n",
    "plt.axvline(x=0.05,color='black')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfb = pd.read_csv(\"base_sample.csv\")\n",
    "dfb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfb.plot(x='Time', y='H2')\n",
    "plt.xlabel(\"Time/ hours\")\n",
    "plt.ylabel(\"Hydrogen/ quantity generated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfb.plot(x='Time', y='Press')\n",
    "plt.xlabel(\"Time/ hours\")\n",
    "plt.ylabel(\"Pressure/ Pa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfb.plot(x='Time', y='Temp')\n",
    "plt.xlabel(\"Time/ hours\")\n",
    "plt.ylabel(\"Tempreature/ K\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data cleaning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set values of input to x\n",
    "X = df_inp.values\n",
    "\n",
    "# set values of output to y_out\n",
    "y_opt = df_out.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a pipeline for scaling and \n",
    "distributions = [\n",
    "    ('Unscaled data', X),\n",
    "    ('Data after standard scaling',\n",
    "        StandardScaler().fit_transform(X)),\n",
    "    ('Data after min-max scaling',\n",
    "        MinMaxScaler().fit_transform(X)),\n",
    "    ('Data after max-abs scaling',\n",
    "        MaxAbsScaler().fit_transform(X)),\n",
    "    ('Data after robust scaling',\n",
    "        RobustScaler(quantile_range=(25, 75)).fit_transform(X)),\n",
    "    ('Data after power transformation (Yeo-Johnson)',\n",
    "     PowerTransformer(method='yeo-johnson').fit_transform(X)),\n",
    "#     ('Data after power transformation (Box-Cox)',\n",
    "#      PowerTransformer(method='box-cox').fit_transform(X)),\n",
    "    ('Data after quantile transformation (uniform pdf)',\n",
    "        QuantileTransformer(output_distribution='uniform')\n",
    "        .fit_transform(X)),\n",
    "    ('Data after quantile transformation (gaussian pdf)',\n",
    "        QuantileTransformer(output_distribution='normal')\n",
    "        .fit_transform(X)),\n",
    "    ('Data after sample-wise L2 normalizing',\n",
    "        Normalizer().fit_transform(X)),\n",
    "]\n",
    "\n",
    "# scale the output between 0 and 1 for the colorbar\n",
    "y = minmax_scale(y_opt)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = data_preprocess(X,y)\n",
    "item_idx = 1 \n",
    "title, X = distributions[item_idx]\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize outliers\n",
    "sn.boxplot( data=X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize outliers\n",
    "sn.boxplot( data=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split(X, y, test_size=0.30)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid for the RandomForestRegressor\n",
    "pipe = RandomForestRegressor()\n",
    "\n",
    "param_grid = {'min_weight_fraction_leaf': Continuous(0.01, 0.5, distribution='log-uniform'),\n",
    "              'bootstrap': Categorical([True, False]),\n",
    "              'max_depth': Integer(2, 30), \n",
    "              'max_leaf_nodes': Integer(2, 35), \n",
    "              'n_estimators': Integer(100, 300)}\n",
    "\n",
    "# Define the GASearchCV options\n",
    "evolved_estimator = GASearchCV(\n",
    "    estimator=pipe,\n",
    "    cv=10,\n",
    "    scoring=\"r2\",\n",
    "    population_size=15,\n",
    "    generations=20,\n",
    "    tournament_size=3,\n",
    "    elitism=True,\n",
    "    keep_top_k=4,\n",
    "    crossover_probability=0.9,\n",
    "    mutation_probability=0.05,\n",
    "    param_grid=param_grid,\n",
    "    criteria=\"max\",\n",
    "    algorithm=\"eaMuCommaLambda\",\n",
    "    n_jobs=-1)\n",
    "\n",
    "#Optionally, create some Callbacks\n",
    "callbacks = [LogbookSaver(checkpoint_path=\"./logbook.pkl\"), ProgressBar()]\n",
    "\n",
    "# Fit the model and see some results\n",
    "evolved_estimator.fit(X_train, y_train, callbacks=callbacks)\n",
    "y_predict_ga = evolved_estimator.predict(X_test)\n",
    "r_squared = r2_score(y_test, y_predict_ga)\n",
    "\n",
    "print(evolved_estimator.best_params_)\n",
    "print(\"r-squared: \", \"{:.2f}\".format(r_squared))\n",
    "print(\"Best k solutions: \", evolved_estimator.hof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = plot_fitness_evolution(evolved_estimator, metric=\"fitness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc(\"text\", usetex=False)\n",
    "plot_search_space(evolved_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[6,5])\n",
    "plt.scatter(y_test, y_predict_ga, s=90)\n",
    "# plt.xlim(left=0.86)\n",
    "# plt.ylim(bottom=0.88, top=0.96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_performance(model_name, y_test, y_predict):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=[8,5], dpi=80)\n",
    "\n",
    "    fig.suptitle(f'Model Performance of {model_name}')\n",
    "    ax1.scatter(y_test, y_predict, s=120, alpha=0.5)\n",
    "    ax1.set_xlim(left=min(y_test))\n",
    "    ax1.set_ylim(bottom=min(y_predict), top=max(y_predict))\n",
    "    ax1.set_xlabel(r'Scaled Actual Output')\n",
    "    ax1.set_ylabel(r'Scaled Predicted Output')\n",
    "    ax1.set_title(r'$R^2 = {:.4g}$'.format(r2_score(y_test, y_predict)))\n",
    "\n",
    "    # best fit of data\n",
    "    data_res = y_test - y_predict \n",
    "    (mu, sigma) = stats.norm.fit(data_res[data_res > min(data_res)])\n",
    "\n",
    "    # the histogram of the data\n",
    "    n, bins, patches = ax2.hist(y_test - y_predict, 30, density=1, alpha=0.5)\n",
    "\n",
    "    # add a 'best fit' line\n",
    "    best_fit_line = scipy.stats.norm.pdf(bins, mu, sigma)\n",
    "    l = ax2.plot(bins, best_fit_line, 'r--', linewidth=2)\n",
    "\n",
    "    ax2.set_xlim(left=min(data_res))\n",
    "    ax2.set_xlabel(r'Residual')\n",
    "    ax2.set_ylabel(r'Frequency')\n",
    "    ax2.set_title(r'$\\sigma = {:.4f}$'.format(mean_squared_error(y_test, y_predict, squared=False)))\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Hydrogen\"\n",
    "plot_model_performance(model_name, y_test[:,0], y_predict_ga[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Temperature\"\n",
    "plot_model_performance(model_name, y_test[:,1], y_predict_ga[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Pressure\"\n",
    "plot_model_performance(model_name, y_test[:,2], y_predict_ga[:,2])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = MLPRegressor()\n",
    "\n",
    "param_grid = {\n",
    "#     'min_weight_fraction_leaf': Continuous(0.01, 0.5, distribution='log-uniform'),\n",
    "#               'bootstrap': Categorical([True, False]),\n",
    "#               'max_depth': Integer(2, 30), \n",
    "#               'max_leaf_nodes': Integer(2, 35), \n",
    "#               'n_estimators': Integer(100, 300)             \n",
    "          'solver': Categorical(['lbfgs', 'sgd', 'adam']),\n",
    "          'max_iter': Integer(500,1500),\n",
    "          'alpha': Continuous(10.0**(-7), 10.0**(-1), distribution='log-uniform'),\n",
    "          'hidden_layer_sizes': Integer(5, 12),\n",
    "          'random_state':Integer(0, 9)\n",
    "             }\n",
    "\n",
    "# Define the GASearchCV options\n",
    "evolved_estimator = GASearchCV(\n",
    "    estimator=pipe,\n",
    "    cv=10,\n",
    "    scoring=\"r2\",\n",
    "    population_size=15,\n",
    "    generations=20,\n",
    "    tournament_size=3,\n",
    "    elitism=True,\n",
    "    keep_top_k=4,\n",
    "    crossover_probability=0.9,\n",
    "    mutation_probability=0.05,\n",
    "    param_grid=param_grid,\n",
    "    criteria=\"max\",\n",
    "    algorithm=\"eaMuCommaLambda\",\n",
    "    n_jobs=-1)\n",
    "\n",
    "#Optionally, create some Callbacks\n",
    "callbacks = [LogbookSaver(checkpoint_path=\"./logbook.pkl\"), ProgressBar()]\n",
    "\n",
    "# Fit the model and see some results\n",
    "evolved_estimator.fit(X_train, y_train, callbacks=callbacks)\n",
    "y_predict_ga = evolved_estimator.predict(X_test)\n",
    "r_squared = r2_score(y_test, y_predict_ga)\n",
    "\n",
    "print(evolved_estimator.best_params_)\n",
    "print(\"r-squared: \", \"{:.2f}\".format(r_squared))\n",
    "print(\"Best k solutions: \", evolved_estimator.hof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = plot_fitness_evolution(evolved_estimator, metric=\"fitness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc(\"text\", usetex=False)\n",
    "plot_search_space(evolved_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[6,5])\n",
    "plt.scatter(y_test, y_predict_ga, s=90)\n",
    "# plt.xlim(left=0.86)\n",
    "# plt.ylim(bottom=0.88, top=0.96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Hydrogen\"\n",
    "plot_model_performance(model_name, y_test[:,0], y_predict_ga[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Temperature\"\n",
    "plot_model_performance(model_name, y_test[:,1], y_predict_ga[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Pressure\"\n",
    "plot_model_performance(model_name, y_test[:,2], y_predict_ga[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the target variables\n",
    "# y_train = np.reshape(y_train, (-1,))\n",
    "# y_test = np.reshape(y_test, (-1,))\n",
    "\n",
    "# # Define a custom scoring metric for R-squared\n",
    "# def r2_score_3d(y_true, y_pred):\n",
    "#     y_true = np.reshape(y_true, (-1,))\n",
    "#     y_pred = np.reshape(y_pred, (-1,))\n",
    "#     return r2_score(y_true, y_pred)\n",
    "\n",
    "# scoring_metric = make_scorer(r2_score_3d)\n",
    "\n",
    "# param_grid = {'n_iter': range(300, 501),\n",
    "#               'tol': np.linspace(0.0001, 0.1, 100),\n",
    "#               'alpha_1': np.linspace(1.0e-7, 1e-1, 100),\n",
    "#               'alpha_2': np.linspace(1.0e-7, 1e-1, 100),\n",
    "#               'lambda_1': np.linspace(1.0e-7, 1e-1, 100),\n",
    "#               'lambda_2': np.linspace(1.0e-7, 1e-1, 100),\n",
    "#               'normalize': [False, True]\n",
    "#               }\n",
    "\n",
    "# pipe = BayesianRidge()\n",
    "\n",
    "\n",
    "# # Create the CV strategy\n",
    "# cv = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "# # Create the EvolutionaryAlgorithmSearchCV object\n",
    "# evolved_estimator = GASearchCV(\n",
    "#     estimator=pipe,\n",
    "#     param_grid=param_grid,\n",
    "#     scoring=scoring_metric,\n",
    "#     cv=cv,\n",
    "#     population_size=50,\n",
    "#     generations=30,\n",
    "#     tournament_size=3,\n",
    "#     elitism=True,\n",
    "#     keep_top_k=4,\n",
    "#     crossover_probability=0.9,\n",
    "#     mutation_probability=0.05,\n",
    "#     verbose=True,\n",
    "#     criteria=\"max\",\n",
    "#     algorithm=\"eaMuCommaLambda\",\n",
    "#     n_jobs=-1\n",
    "# )\n",
    "\n",
    "# #Optionally, create some Callbacks\n",
    "# callbacks = [LogbookSaver(checkpoint_path=\"./logbook.pkl\"), ProgressBar()]\n",
    "\n",
    "# # Fit the model and see some results\n",
    "# evolved_estimator.fit(X_train, y_train, callbacks=callbacks)\n",
    "# y_predict_ga = evolved_estimator.predict(X_test)\n",
    "# y_predict_ga = np.reshape(y_predict_ga, y_test.shape)\n",
    "# r_squared = r2_score_3d(y_test, y_predict_ga)\n",
    "\n",
    "# print(evolved_estimator.best_params_)\n",
    "# print(\"r-squared: \", \"{:.2f}\".format(r_squared))\n",
    "# print(\"Best k solutions: \", evolved_estimator.hof)\n",
    "\n",
    "param_grid = {'n_iter': Integer(300, 500),\n",
    "              'tol': Continuous(0.0001, 0.1),\n",
    "              'alpha_1': Continuous(1.0e-7, 1e-1),\n",
    "              'alpha_2': Continuous(1.0e-7, 1e-1),\n",
    "              'lambda_1': Continuous(1.0e-7, 1e-1),\n",
    "              'lambda_2': Continuous(1.0e-7, 1e-1),\n",
    "              'normalize': Categorical([False, True])}\n",
    "\n",
    "\n",
    "\n",
    "pipe = BayesianRidge()\n",
    "\n",
    "# param_grid = {'min_weight_fraction_leaf': Continuous(0.01, 0.5, distribution='log-uniform'),\n",
    "#               'bootstrap': Categorical([True, False]),\n",
    "#               'max_depth': Integer(2, 30), \n",
    "#               'max_leaf_nodes': Integer(2, 35), \n",
    "#               'n_estimators': Integer(100, 300)}\n",
    "# Create the CV strategy and define the param grid\n",
    "cv = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "# Define the GASearchCV options\n",
    "evolved_estimator = GASearchCV(\n",
    "    estimator=pipe,\n",
    "    cv=cv,\n",
    "    scoring=\"r2\",\n",
    "    population_size=15,\n",
    "    generations=20,\n",
    "    tournament_size=3,\n",
    "    elitism=True,\n",
    "    keep_top_k=4,\n",
    "    crossover_probability=0.9,\n",
    "    mutation_probability=0.05,\n",
    "    param_grid=param_grid,\n",
    "#     param_grid=None,\n",
    "    criteria=\"max\",\n",
    "    algorithm=\"eaMuCommaLambda\",\n",
    "    n_jobs=-1)\n",
    "\n",
    "#Optionally, create some Callbacks\n",
    "callbacks = [LogbookSaver(checkpoint_path=\"./logbook.pkl\"), ProgressBar()]\n",
    "\n",
    "# Fit the model and see some results\n",
    "evolved_estimator.fit(X_train, y_train, callbacks=callbacks)\n",
    "y_predict_ga = evolved_estimator.predict(X_test)\n",
    "r_squared = r2_score(y_test, y_predict_ga)\n",
    "\n",
    "print(evolved_estimator.best_params_)\n",
    "print(\"r-squared: \", \"{:.2f}\".format(r_squared))\n",
    "print(\"Best k solutions: \", evolved_estimator.hof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = plot_fitness_evolution(evolved_estimator, metric=\"fitness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc(\"text\", usetex=False)\n",
    "plot_search_space(evolved_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[6,5])\n",
    "plt.scatter(y_test, y_predict_ga, s=90)\n",
    "# plt.xlim(left=0.86)\n",
    "# plt.ylim(bottom=0.88, top=0.96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Hydrogen\"\n",
    "plot_model_performance(model_name, y_test[:,0], y_predict_ga[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Temperature\"\n",
    "plot_model_performance(model_name, y_test[:,1], y_predict_ga[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Pressure\"\n",
    "plot_model_performance(model_name, y_test[:,2], y_predict_ga[:,2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "b119d6cc3476f76004f7d264cfcd5d8d36e9da707c7162ae9969d1410f0eccce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
